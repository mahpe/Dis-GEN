{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b33e461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 07:39:26.328883: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-16 07:39:26.526719: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-16 07:39:26.563302: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-16 07:39:26.563364: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-16 07:39:26.563397: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-16 07:39:26.571499: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-16 07:39:26.571996: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-16 07:39:36.939391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from ase.io import read, write\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from pymatgen.core import Lattice, Structure, Molecule\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from pymatgen.core import PeriodicSite\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pymatgen.core import Composition, Structure\n",
    "from typing import List, Tuple\n",
    "\n",
    "import re, joblib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from pyxtal.symmetry import Group\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from ase.io import read, write\n",
    "from ase import Atoms\n",
    "from ase.data import chemical_symbols\n",
    "from ase.db import connect\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from spglib import get_spacegroup, find_primitive, standardize_cell\n",
    "import pymatgen \n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "import ast\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import roc_curve, auc,accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score # for cross-validation\n",
    "from datetime import datetime \n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder, StandardScaler\n",
    "from pymatgen.core import Composition, Structure\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from pymatgen.io.cif import CifParser\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from pymatgen.io.cif import CifWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "sys.path.append('/home/energy/mahpe/Published_code/Dis-CSP/dis_csp')\n",
    "\n",
    "from dis_csp.model import CrystalDataset, VAE\n",
    "from dis_csp.generation import decode_samples, generate_wyckoffgene, get_cif_lines, generate_cif_files\n",
    "from dis_csp.csp_filter import structure_validity,oxidation_state_validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad926ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latent space samples from /home/energy/mahpe/Published_code/Dis-CSP/Decoded_data/z_samples_gmm.npy\n",
      "Loading Y_scaler from file Y_scaler.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/energy/mahpe/Published_code/Dis-CSP/dis_csp/generation.py:148: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'disordered_site': F.sigmoid(torch.tensor(disordered_site)).cpu().detach().numpy(),\n"
     ]
    }
   ],
   "source": [
    "latent_space_path = '/home/energy/mahpe/Published_code/Dis-CSP/Decoded_data/z_samples_gmm.npy'\n",
    "model_dir = 'New_Kl5_ICSD_dis_site_middle_KL_element1000_lr_5e-06_epochs_2500_batch_64_test_0.2_val_0.1'\n",
    "best_model = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "### Load the VAE model ###\n",
    "if best_model:\n",
    "    vae_dict = torch.load(model_dir+'/best_vae_model.pth',map_location=torch.device('cpu'))\n",
    "else: # use exit model\n",
    "    vae_dict = torch.load(model_dir+'/exit_vae_model.pth',map_location=torch.device('cpu'))\n",
    "\n",
    "feature_dim = 183\n",
    "wyckoff_dim = 9\n",
    "crystal_dim = 236\n",
    "kernel = [5,3,2]\n",
    "stride = [2,3,2]\n",
    "max_filter = 16\n",
    "latent_dim = 256\n",
    "vae_eval = VAE(feature_dim, wyckoff_dim, crystal_dim,verbose=False,kernel=kernel,stride=stride)\n",
    "vae_eval.load_state_dict(vae_dict['model'])\n",
    "\n",
    "# Decode the latent space samples\n",
    "#latent_space_path = 'Decoded_data/z_samples_kde_optimized.npy'\n",
    "cif_save_path = 'Decoded_data/Generated_cif'\n",
    "print(f\"Loading latent space samples from {latent_space_path}\")\n",
    "z_samples = np.load(latent_space_path)\n",
    "\n",
    "if 'Y_scaler' in vae_dict:\n",
    "    scaler_Y = vae_dict['Y_scaler']\n",
    "else:\n",
    "    # Load the scaler if not present in the model dictionary\n",
    "    print('Loading Y_scaler from file Y_scaler.gz')\n",
    "    scaler_Y = joblib.load('Y_scaler.gz')\n",
    "\n",
    "### Load the latent space samples ###\n",
    "z_samples = np.load(latent_space_path)\n",
    "\n",
    "# Get the decoded samples\n",
    "save_dict = decode_samples(z_samples,vae_eval,scaler_Y,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86bf6e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27008/27008 [08:06<00:00, 55.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetry Matching Accuracy: 20.35%\n",
      "Number of failed items: 460 of 27008 processed, Procentage: 1.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate Wyckoff genes\n",
    "mixiter = None\n",
    "element_acc = 0.05  \n",
    "disorder_acc = 0.5\n",
    "all_wyckoffgenes,sma_int, failed_int = generate_wyckoffgene(save_dict,\n",
    "                             max_iter=mixiter,\n",
    "                             element_acc=element_acc,\n",
    "                             disorder_acc=disorder_acc,\n",
    "                             shift_frac_coord=True,\n",
    "                             verbose=False)\n",
    "if mixiter is not None:\n",
    "    print(f\"Symmetry Matching Accuracy: {100-sma_int/mixiter*100:.2f}%\")\n",
    "    print(f\"Number of failed items: {failed_int} of {mixiter} processed, Procentage: {failed_int/mixiter*100:.2f}%\")\n",
    "else:\n",
    "    print(f\"Symmetry Matching Accuracy: {100- sma_int/len(save_dict['spacegroup'])*100:.2f}%\")\n",
    "    print(f\"Number of failed items: {failed_int} of {len(save_dict['spacegroup'])} processed, Procentage: {failed_int/len(save_dict['spacegroup'])*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e8ba1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 27008 structures out of 5035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5035/5035 [02:13<00:00, 37.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse 0 structures out of 27008 Procentage: 100.00%\n",
      "Validity check failed for 1244 structures out of 27008 Procentage: 95.39%\n",
      "Oxidation state check failed for 1468 structures out of 27008 Procentage: 94.56%\n",
      "Total valid structures: 2895 out of 27008 Procentage: 10.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "len_all_structures = len(save_dict['spacegroup'])\n",
    "all_cifs,cifs__wyckoffgene = generate_cif_files(all_wyckoffgenes,maxiter=len_all_structures,validity_primitive=False,symmetry_analyzer=False, verbose=False, two_oxidation_state=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sylg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
